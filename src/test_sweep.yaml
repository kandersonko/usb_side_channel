command:
  - ${env}
  - python3
  - ${program}
  - ${args_no_boolean_flags}
program: classifier.py
method: bayes
metric:
  goal: maximize
  name: val_acc
parameters:
  # dataset
  dataset:
    distribution: categorical
    values:
      - dataset_d1
  method:
    distribution: categorical
    values:
      - raw
  target_label:
    distribution: categorical
    values:
      - device
  classifier:
    distribution: categorical
    values:
      - lstm
  base_model:
    # values: ["parallel_cnn_lstm", "cnn_lstm", "lstm_cnn", "lstm"]
    values: ["parallel_cnn_lstm"]
  task:
    distribution: categorical
    values:
      - identification
  model_name:
    distribution: categorical
    values:
      - lstm-encoder
  conv1_out_channels:
    distribution: int_uniform
    max: 128
    min: 8
  conv2_out_channels:
    distribution: int_uniform
    max: 128
    min: 8
  bottleneck_dim:
    distribution: int_uniform
    max: 128
    min: 8
  num_lstm_layers:
    values: [1, 2, 4]
  use_batch_norm:
    values:
      - true
      - false
  dropout:
    values: [0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6]
  accumulate_grad_batches:
    values: [1, 2, 4]
  batch_size:
    # values: [8, 16, 32]
    values:
      - 16
  learning_rate:
    values: [1e-3]
  log:
    values:
      - true
  tuning:
    values:
      - true
  max_epochs:
    distribution: categorical
    values:
      - 50
  min_epochs:
    distribution: categorical
    values:
      - 10
  monitor_metric:
    distribution: categorical
    values:
      - val_loss
  num_classes:
    distribution: categorical
    values:
      - 4
